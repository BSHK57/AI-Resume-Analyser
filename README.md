# AI Resume Analyzer & Scorer

## 🎯 Objective

This project is a Flask-based web application designed to analyze resumes against job descriptions. It provides a match score and a summary of strengths and weaknesses for each resume, generated by an AI language model.

---

### ✨ Key Features:

1.  **Upload Multiple Resumes**: Supports PDF and DOCX file formats.
2.  **Job Description Input**: Accepts job descriptions via a textarea.
3.  **Content Analysis**: Extracts and analyzes text from uploaded resumes.
4.  **Output Generation**:
    *   **Match Score**: A percentage (0–100) indicating how well the resume matches the job description, calculated using TF-IDF and cosine similarity.
    *   **AI-Generated Summary**: Identifies key fit points and potential gaps using a Google Gemini model (e.g., gemini-pro).
5.  **Ranked Display**: Shows a list of resumes, ranked by their match score.

---

### ⚙️ Tech Stack:

*   **Backend**: Flask
*   **Frontend**: HTML, CSS, Bootstrap
*   **AI/NLP**:
    *   Google Gemini API (e.g., gemini-pro) for summary generation.
    *   `nltk` for text preprocessing (tokenization, stopwords, lemmatization).
    *   `scikit-learn` for TF-IDF vectorization and cosine similarity scoring.
    *   `pdfplumber` for parsing PDF files.
    *   `docx2txt` for parsing DOCX files.
    *   (`spacy` is included in `requirements.txt` for potential future use).
*   **File Uploads**: Handled via Flask and stored temporarily in an `uploads/` directory.

---

### 📂 Project Structure:

```
resume-analyzer/
├── app.py                # Main Flask application
├── templates/
│   └── index.html        # Frontend HTML template
├── static/
│   └── styles.css        # Custom CSS styles
├── utils/
│   ├── resume_parser.py  # Logic for extracting text from resumes
│   ├── scorer.py         # Logic for calculating match scores
│   └── llm_summary.py    # Logic for generating AI summaries
├── uploads/              # Temporary storage for uploaded resumes (should be in .gitignore)
├── requirements.txt      # Python package dependencies
└── README.md             # This file
```

---

### 🚀 Getting Started:

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd resume-analyzer
    ```

2.  **Create and activate a virtual environment:**
    ```bash
    python -m venv venv
    # On Windows
    # venv\Scripts\activate
    # On macOS/Linux
    # source venv/bin/activate
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *Note: This will install `nltk`. The first time `scorer.py` runs, it will attempt to download necessary NLTK data (`stopwords`, `wordnet`, `punkt`). If you encounter issues, you might need to run Python and download them manually:*
    ```python
    import nltk
    nltk.download('stopwords')
    nltk.download('wordnet')
    nltk.download('punkt')
    ```

4.  **Set up Google Gemini API Key:**
    The application uses the Google Gemini API for generating summaries. You need to set your API key as an environment variable:
    ```bash
    export GEMINI_API_KEY='your_actual_gemini_api_key_here'
    # For Windows (Command Prompt)
    # set GEMINI_API_KEY=your_actual_gemini_api_key_here
    # For Windows (PowerShell)
    # $env:GEMINI_API_KEY="your_actual_gemini_api_key_here"
    ```
    If the API key is not set, summaries will not be generated, and an error message will be displayed in their place.

5.  **Run the Flask application:**
    ```bash
    python app.py
    ```

6.  Open your web browser and navigate to `http://127.0.0.1:5000/`.

---

### 📝 Notes:

*   The `uploads/` directory is used for temporary storage of resumes. It's recommended to add this directory to your `.gitignore` file if it's not already.
*   The AI-generated summaries depend on the Google Gemini API. Ensure you have a valid API key.
*   The scoring mechanism uses TF-IDF and cosine similarity. Preprocessing steps like stopword removal and lemmatization are applied to improve relevance.

```
